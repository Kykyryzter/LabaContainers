# Lab_STL

Ход работы:

**№0 Сравнение capacity и size(top) от i**

0) Создадим рабочий набор значений.

   С помощью файла *randomData* создадим *Data.txt*, в котором будем хранить обрабатываемый набор данных. В *Data.txt* 100000 значений, объемом 651 кб.

1) Создадим рукописную функцию std_vector - MyVector.

   Данный код будет работать следующим образом - для начала мы считаем данные с файла *Data.txt* в массив. После чего запустим цикл, в котором будет работать функция *push_back, push_top, push_capacity*; при этом выводя в отдельные файлы *MyVectorIteration.txt, MyVectorTop.txt, MyVectorCapacity.txt* значения номера итерации, заполненность и размер емкости вектора соответсвенно.

2) Повторим пункт 1 для std::vector; назовем функцию - *Vector*.

   Принцип действия аналогичный. Запишем данные в *VectorIteration.txt, VectorTop.txt, VectorCapacity.txt*

   Построим графики, в которой отбразим зависимость *size* и *capasity* от номера итерации функций *MyVector* и *Vector*

**№1 Среднее время вставки элемента в произвольное место вектора**

0) Принцип работы не сильно будет отличаться от задания №0. Для произвольности создадим с помощью *insert* набор данных, который будет определять, в какое место вектора нужно вставить элемент.

   Получим набор данных *Insert.txt*

1) Напишем функцию для вставки в *MyVector* элемента, с указанием позиции вставки. Будем выводить каждые 1000 итераций количество элементов в векторе и время, которое было затрачено на вставку 1000 элементов. Код - *1_MyVector_Random_Insert.cpp*, полученные значения в *MyVector_RandomInsert_Size.txt* *MyVector_RandomInsert_Time.txt*

2) Проделаем подобную работу для std::Vector

   Построим графики зависимости времени вставки 1000 элементов от размера вектора.

   Несложно определить ассимпототику. Для *MyVector* она составляет O(N), для *STD Vector* - O(N)

   Мой Вектор выдает большие затраты по времени и и почти идеальную линиейную зависимость от *size* из-за конструкции функции. Каждый раз компилятор создает, грубо говоря, новый вектор и заполняет его с нужным элементом в нужном месте.

   STD Вектор тоже имеет зависиомть линейную, однако она суммируется из константной переменной и разницы между позиции вставки и количеством элементов в векторе. То есть затраченное время всегда будет не больше чем у Моего Вектора.

**№2 Удаление рандомного элемента из вектора**

0) Опять же аналогичный принцип. Создаем функцию *erase* для *MyVector*. Проводим измерения. Выводим полученные значения в документ

1) Аналогично для std Vector

2) Строим графики зависмости времени удаления элемента от размера вектора.

   Мой вектор выдает странную колеблющуюся функцию с асимптотикой o(N).

   STD вектор выдает также O(N) однако суммируется она между разницей элементов от выбранного значения до *top* и единичной асимптотики, т.е всегда будет затрачивать не больше времени чем *MyVector*

**№3 Добавление элемента в начало списка**

0) Для данного задания создадим новый набор данных из 5.000.000 элементов - *Data5mil.txt*. Будем брать значение времени вставки 50.000 элементов. (вставка 1.000 элементов происходит слишком быстро).

   К сожалению, добавить файл *Data5mil.txt* я не могу (слишком большой объем), но создан он аналогично п.0

1) Будем исследовать контейнеры STL - List, ForwardList, а также рукописный контейнер с 1го семестра - SubForwardList

2) Построим график зависимости времени добавления элемента в начало списка от размера списка. Можно заметить, что асимптотика не зависит от размера *List*, однако рукописный список показывает не большое превосходство во времени. Асимптотика для всех трех типов - О(1)

**№4 Удаление элемента из начала списка**

0) Задание полностью аналогично предыдущему.

1) Графики не зависят от размера списка. Во времени работы значительной разнийы между различными видами списка не наблюдается. Асимптотика - О(1)

**№5 Добавление элемента в бинанрное дерево**

Данное задание прошло для меня несколько иначе, чем предыдущие. Так что исследуем слегка иначе

0) Для начала - работа с *set* и *map*. Для данных контейнеров я использовал набор данных - *data.txt* из 100.000 элементов, однако и для такого количество наблюдались повторения. Из-за того что файл *data.txt* был собран с помошью рандомных значений, наблюдались повторения даже спустя 1000 итераций.

P.S. Данную работу я выполнял на одном и том же коде, так что на гитхаб добавил лишь код для *multimap*, для остальных видов деревей он был аналогичным

1) Для контейнеров *multiset* и *multimap* я использовал набор данных - *data5mil.txt* из 5.000.000 элементов. В данном случае проблем не наблюдалось

2) Построим графики зависимости времени выполнения *insert* от *size*.

   Для *map* и *set* не удалось получить красивых графиков из-за невозможности добавлений одинаковых значений. Асимптотика - O(log(N))

   А вот для *multimap* и *multiset* получились максимально наглядные графики. С уверенностью можно обозначить асимптотику O(log(N)). Для *Multimap* получился график, как будто суженный в 2 раз для *multiset*

**№6 Среднее время обхода контейнеров**

0) Аналогично прошлому заданию, для каждого отдельного контейнера я не создавал кода, лишь изменял для того или иного случая.

  Вектор я перебирал с помощью [], остальные же контейнеры обходились с помощью итератора.

  Также вместо *set* и *map* я использовал контейнеры *multimap* и *multiset*, т.к. их зависимость от размера мне показалась более показательной.

1) Построил графика. Из-за того, что для вектора доступ к элементу равен 0(1), какая-либо зависимость времени обхода от размера не наблюдалась. Для остальных же контейнеров можно четко увидеть увеличение времени с увеличением размера.

**№7 Доступ к случайному элементу**

0) Принцип работы следующий: создаем набор данных *Random_Access*, где каждое значение не больше размера контейнера. Это будет для нас генератором рандомного места вектора. После чего добавляем значени в контейнер и замеряем время.

1) SubVector из-за своей структуры получился крайне времезатратнным, поэтому была получена зависимость до 380.000 элементов(при большем значении компилятор просто вылетал). Будем фиксировать время каждые 4.000 элемента, т.е итерируем 4.000 раз схему добавление элемента-старта отсчета-поиск элемента-конец отсчета, после чего выводим время, затраченное на поиск элемента, в отдельный документ. Получился график, на котором можно увидеть незначительную пропорцианальную зависимость времени поиска элемента от размера контейнера.

2) С *Vector* все намного проще. Было внесено 5.000.000 значений в контейнер. Рассчет проводились аналогично предыдущему пункту, однако выводил значения раз в 50.000 итераций. График показателен. Все происходит настолько быстро, что компилятор просто не смог засечь время.


   

